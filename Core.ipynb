{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 1.11.0 _CudaDeviceProperties(name='NVIDIA GeForce RTX 3080', major=8, minor=6, total_memory=10239MB, multi_processor_count=68)\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "from torch import nn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.models import resnet\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/halfendt/dog-breed-classifier-pytorch-resnet-152\n",
    "def load_transform_images(images_path, presplit, train_split, test_split, val_split, batch_size, threads, mean, std):\n",
    "    train_transform = transforms.Compose([\n",
    "                                         #transforms.RandomRotation(degrees=15),\n",
    "                                         #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                                         #transforms.RandomResizedCrop((224,224)),\n",
    "                                         transforms.Resize((224,224)),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(torch.Tensor(mean),\n",
    "                                                              torch.Tensor(std))])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "                                        transforms.Resize((224,224)),\n",
    "                                        #transforms.CenterCrop((224,224)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(torch.Tensor(mean),\n",
    "                                                             torch.Tensor(std))])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "                                       transforms.Resize((224,224)),\n",
    "                                       #transforms.CenterCrop((224,224)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(torch.Tensor(mean),\n",
    "                                                            torch.Tensor(std))])\n",
    "\n",
    "    if presplit:\n",
    "        try:\n",
    "            training_set = datasets.ImageFolder(root=images_path+'/train', transform=train_transform)\n",
    "            validation_set = datasets.ImageFolder(root=images_path+'/val', transform=val_transform)\n",
    "        except FileNotFoundError:\n",
    "            raise Exception('Not presplit into Training and Validation sets')\n",
    "        try:\n",
    "            testing_set = datasets.ImageFolder(root=images_path+'/test', transform=test_transform)\n",
    "        except:\n",
    "            testing_set = validation_set\n",
    "        dataset = training_set\n",
    "    else:\n",
    "        dataset = datasets.ImageFolder(root=images_path, transform=train_transform)\n",
    "        train_size = int(train_split * len(dataset))\n",
    "        test_size = int(test_split * len(dataset))\n",
    "        val_size = len(dataset) - train_size - test_size\n",
    "        training_set, testing_set, validation_set = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "    training_set_loader = DataLoader(training_set, batch_size=batch_size, num_workers=threads, shuffle=True)\n",
    "    validation_set_loader = DataLoader(validation_set, batch_size=batch_size, num_workers=threads, shuffle=True)\n",
    "    testing_set_loader = DataLoader(testing_set, batch_size=batch_size, num_workers=threads, shuffle=False)\n",
    "\n",
    "    return training_set_loader, testing_set_loader, validation_set_loader, dataset, training_set, testing_set, validation_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "images_path = './data/images/Images/'\n",
    "results_path = images_path+'_results'\n",
    "presplit = False\n",
    "train_split = 0.7\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "batch_size = 32\n",
    "threads = 0\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "training_set_loader, testing_set_loader, validation_set_loader, dataset, training_set, testing_set, validation_set = \\\n",
    "                  load_transform_images(images_path, presplit, train_split, test_split, val_split, batch_size, threads, mean, std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "from torch.nn import init\n",
    "import math\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "\treturn nn.Sequential(\n",
    "\t\tnn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "\t\tnn.BatchNorm2d(oup),\n",
    "\t\tnn.ReLU(inplace=True)\n",
    "\t)\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "\treturn nn.Sequential(\n",
    "\t\tnn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "\t\tnn.BatchNorm2d(oup),\n",
    "\t\tnn.ReLU(inplace=True)\n",
    "\t)\n",
    "\n",
    "def channel_shuffle(x, groups):\n",
    "\tbatchsize, num_channels, height, width = x.data.size()\n",
    "\n",
    "\tchannels_per_group = num_channels // groups\n",
    "\n",
    "\t# reshape\n",
    "\tx = x.view(batchsize, groups,\n",
    "\t\tchannels_per_group, height, width)\n",
    "\n",
    "\tx = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "\t# flatten\n",
    "\tx = x.view(batchsize, -1, height, width)\n",
    "\n",
    "\treturn x\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "\tdef __init__(self, inp, oup, stride, benchmodel):\n",
    "\t\tsuper(InvertedResidual, self).__init__()\n",
    "\t\tself.benchmodel = benchmodel\n",
    "\t\tself.stride = stride\n",
    "\t\tassert stride in [1, 2]\n",
    "\n",
    "\t\toup_inc = oup//2\n",
    "\n",
    "\t\tif self.benchmodel == 1:\n",
    "\t\t\t#assert inp == oup_inc\n",
    "\t\t\tself.banch2 = nn.Sequential(\n",
    "\t\t\t\t# pw\n",
    "\t\t\t\tnn.Conv2d(oup_inc, oup_inc, 1, 1, 0, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(oup_inc),\n",
    "\t\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\t\t# dw\n",
    "\t\t\t\tnn.Conv2d(oup_inc, oup_inc, 3, stride, 1, groups=oup_inc, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(oup_inc),\n",
    "\t\t\t\t# pw-linear\n",
    "\t\t\t\tnn.Conv2d(oup_inc, oup_inc, 1, 1, 0, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(oup_inc),\n",
    "\t\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tself.banch1 = nn.Sequential(\n",
    "\t\t\t\t# dw\n",
    "\t\t\t\tnn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(inp),\n",
    "\t\t\t\t# pw-linear\n",
    "\t\t\t\tnn.Conv2d(inp, oup_inc, 1, 1, 0, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(oup_inc),\n",
    "\t\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\tself.banch2 = nn.Sequential(\n",
    "\t\t\t\t# pw\n",
    "\t\t\t\tnn.Conv2d(inp, oup_inc, 1, 1, 0, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(oup_inc),\n",
    "\t\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\t\t# dw\n",
    "\t\t\t\tnn.Conv2d(oup_inc, oup_inc, 3, stride, 1, groups=oup_inc, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(oup_inc),\n",
    "\t\t\t\t# pw-linear\n",
    "\t\t\t\tnn.Conv2d(oup_inc, oup_inc, 1, 1, 0, bias=False),\n",
    "\t\t\t\tnn.BatchNorm2d(oup_inc),\n",
    "\t\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\t)\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef _concat(x, out):\n",
    "\t\t# concatenate along channel axis\n",
    "\t\treturn torch.cat((x, out), 1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tif 1==self.benchmodel:\n",
    "\t\t\tx1 = x[:, :(x.shape[1]//2), :, :]\n",
    "\t\t\tx2 = x[:, (x.shape[1]//2):, :, :]\n",
    "\t\t\tout = self._concat(x1, self.banch2(x2))\n",
    "\t\telif 2==self.benchmodel:\n",
    "\t\t\tout = self._concat(self.banch1(x), self.banch2(x))\n",
    "\n",
    "\t\treturn channel_shuffle(out, 2)\n",
    "\n",
    "\n",
    "class ShuffleNetV2(nn.Module):\n",
    "\tdef __init__(self, n_class=120, input_size=224, width_mult=1.):\n",
    "\t\tsuper(ShuffleNetV2, self).__init__()\n",
    "\n",
    "\t\tassert input_size % 32 == 0\n",
    "\n",
    "\t\tself.stage_repeats = [4, 8, 4]\n",
    "\t\t# index 0 is invalid and should never be called.\n",
    "\t\t# only used for indexing convenience.\n",
    "\t\tif width_mult == 0.5:\n",
    "\t\t\tself.stage_out_channels = [-1, 24,  48,  96, 192, 1024]\n",
    "\t\telif width_mult == 1.0:\n",
    "\t\t\tself.stage_out_channels = [-1, 24, 116, 232, 464, 1024]\n",
    "\t\telif width_mult == 1.5:\n",
    "\t\t\tself.stage_out_channels = [-1, 24, 176, 352, 704, 1024]\n",
    "\t\telif width_mult == 2.0:\n",
    "\t\t\tself.stage_out_channels = [-1, 24, 224, 488, 976, 2048]\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(\n",
    "\t\t\t\t\"\"\"{} groups is not supported for\n",
    "\t\t\t\t\t   1x1 Grouped Convolutions\"\"\".format(3))\n",
    "\n",
    "\t\t# building first layer\n",
    "\t\tinput_channel = self.stage_out_channels[1]\n",
    "\t\tself.conv1 = conv_bn(3, input_channel, 2)\n",
    "\t\tself.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\t\tself.features = []\n",
    "\t\t# building inverted residual blocks\n",
    "\t\tfor idxstage in range(len(self.stage_repeats)):\n",
    "\t\t\tnumrepeat = self.stage_repeats[idxstage]\n",
    "\t\t\toutput_channel = self.stage_out_channels[idxstage+2]\n",
    "\t\t\tfor i in range(numrepeat):\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t#inp, oup, stride, benchmodel):\n",
    "\t\t\t\t\tself.features.append(InvertedResidual(input_channel, output_channel, 2, 2))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.features.append(InvertedResidual(input_channel, output_channel, 1, 1))\n",
    "\t\t\t\tinput_channel = output_channel\n",
    "\n",
    "\n",
    "\t\t# make it nn.Sequential\n",
    "\t\tself.features = nn.Sequential(*self.features)\n",
    "\n",
    "\t\t# building last several layers\n",
    "\t\tself.conv_last      = conv_1x1_bn(input_channel, self.stage_out_channels[-1])\n",
    "\t\tself.globalpool = nn.Sequential(nn.AvgPool2d(int(input_size/32)))\n",
    "\n",
    "\t# building classifier\n",
    "\t\tself.classifier = nn.Sequential(nn.Linear(self.stage_out_channels[-1], n_class))\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.maxpool(x)\n",
    "\t\tx = self.features(x)\n",
    "\t\tx = self.conv_last(x)\n",
    "\t\tx = self.globalpool(x)\n",
    "\t\tx = x.view(-1, self.stage_out_channels[-1])\n",
    "\t\tx = self.classifier(x)\n",
    "\t\treturn x\n",
    "\n",
    "def shufflenetv2(width_mult=1.):\n",
    "\tmodel = ShuffleNetV2(width_mult=width_mult)\n",
    "\treturn model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def validate():\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor imgs, labels in validation_set_loader:\n",
    "\t\t\timgs = imgs.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\t\t\tbatch_size=imgs.shape[0]\n",
    "\t\t\toutputs = model(imgs)\n",
    "\t\t\t_, predicted = torch.max(outputs, dim=1)\n",
    "\t\t\ttotal += labels.shape[0]\n",
    "\t\t\tcorrect += int((predicted==labels).sum())\n",
    "\t\tprint(\"Accuracy \", correct/total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import time\n",
    "def training(model, optimizer, loss_fn, n_epochs, device, l2_lambda, train_loader):\n",
    "\tstart = time.time()\n",
    "\n",
    "\tfor epoch in range(n_epochs):\n",
    "\t\tif epoch == 75:\n",
    "\t\t\tlearning_rate = 1e-5\n",
    "\t\t\tvalidate()\n",
    "\t\t\tmodel.train()\n",
    "\t\telif epoch == 100:\n",
    "\t\t\tlearning_rate = 1e-6\n",
    "\t\t\tvalidate()\n",
    "\t\t\tmodel.train()\n",
    "\t\telif epoch == 10:\n",
    "\t\t\tlearning_rate = 1e-4\n",
    "\t\t\tvalidate()\n",
    "\t\t\tmodel.train()\n",
    "\t\telif epoch == 50:\n",
    "\t\t\tlearning_rate = 1e-4\n",
    "\t\t\tvalidate()\n",
    "\t\t\tmodel.train()\n",
    "\t\tfor imgs, labels in train_loader:\n",
    "\t\t\timgs = imgs.to(device)\n",
    "\t\t\tlabels = labels.to(device)\n",
    "\t\t\tbatch_size = imgs.shape[0]\n",
    "\t\t\toutputs = model(imgs)\n",
    "\t\t\tloss = loss_fn((outputs), labels)\n",
    "\t\t\tl2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "\t\t\tloss = loss + l2_lambda* l2_norm\n",
    "\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\tprint(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "\tend = time.time()\n",
    "\tprint(end - start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = shufflenetv2(2.0).to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_epochs = 150\n",
    "l2_lambda = .001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training(model, optimizer, loss_function, n_epochs, device, l2_lambda, training_set_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/150epochStandardAdaptiveLRWide.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "macs, params = get_model_complexity_info(model, ( 3, 224,224), as_strings=True, print_per_layer_stat=False, verbose=False)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}